{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38b8e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample MicroSeries created:\n",
      "Data shape: (1000,)\n",
      "Weights shape: (1000,)\n",
      "MicroSeries type: <class 'microdf.generic.MicroSeries'>\n",
      "First 5 values: 0    109.934283\n",
      "1     97.234714\n",
      "2    112.953771\n",
      "3    130.460597\n",
      "4     95.316933\n",
      "dtype: float64\n",
      "First 5 weights: 0    0.183301\n",
      "1    0.110449\n",
      "2    1.011784\n",
      "3    1.225795\n",
      "4    0.032096\n",
      "dtype: float64\n",
      "Weights sum: 1007.9859336968675\n",
      "All weights are zero: False\n",
      "✓ Weights are properly initialized\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from microdf import MicroSeries\n",
    "\n",
    "# Create sample data for testing\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(100, 20, 1000)\n",
    "weights = np.random.exponential(1, 1000)\n",
    "\n",
    "# Create MicroSeries instance\n",
    "ms = MicroSeries(data, weights=weights)\n",
    "\n",
    "print(\"Sample MicroSeries created:\")\n",
    "print(f\"Data shape: {ms.shape}\")\n",
    "print(f\"Weights shape: {ms.weights.shape}\")\n",
    "print(f\"MicroSeries type: {type(ms)}\")\n",
    "print(f\"First 5 values: {ms.head()}\")\n",
    "print(f\"First 5 weights: {ms.weights.head()}\")\n",
    "print(f\"Weights sum: {ms.weights.sum()}\")\n",
    "print(f\"All weights are zero: {(ms.weights == 0).all()}\")\n",
    "\n",
    "# Safety check: ensure weights are not zero\n",
    "if ms.weights.sum() == 0:\n",
    "    print(\"⚠️  ERROR: Weights sum to zero! This should not happen with exponential distribution.\")\n",
    "    print(\"⚠️  Recreating with explicit positive weights...\")\n",
    "    ms = MicroSeries(data, weights=np.ones(len(data)))\n",
    "    print(f\"Fixed weights sum: {ms.weights.sum()}\")\n",
    "else:\n",
    "    print(\"✓ Weights are properly initialized\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aac4746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASIC STATISTICAL OPERATIONS ===\n",
      "\n",
      "sum(): 101015.38419115798\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "count(): 1007.9859336968675\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "mean(): 100.21507326067153\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "median(): 101.37310698663197\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "gini(): 0.10798101497882602\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "gini(negatives='zero'): 0.10798101497882602\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "=== QUANTILE OPERATIONS ===\n",
      "\n",
      "quantile(0.5): 101.37310698663197\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "quantile([0.25, 0.5, 0.75]): 0.25     87.986469\n",
      "0.50    101.373107\n",
      "0.75    112.444198\n",
      "dtype: float64\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Basic Statistical Operations (scalar functions)\n",
    "print(\"=== BASIC STATISTICAL OPERATIONS ===\\n\")\n",
    "\n",
    "# sum()\n",
    "result = ms.sum()\n",
    "print(f\"sum(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# count()\n",
    "result = ms.count()\n",
    "print(f\"count(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# mean()\n",
    "result = ms.mean()\n",
    "print(f\"mean(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# median()\n",
    "result = ms.median()\n",
    "print(f\"median(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# gini()\n",
    "result = ms.gini()\n",
    "print(f\"gini(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# gini() with negatives handling\n",
    "result = ms.gini(negatives=\"zero\")\n",
    "print(f\"gini(negatives='zero'): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Test 2: Quantile operations\n",
    "print(\"=== QUANTILE OPERATIONS ===\\n\")\n",
    "\n",
    "# quantile() with single value\n",
    "result = ms.quantile(0.5)\n",
    "print(f\"quantile(0.5): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# quantile() with array\n",
    "result = ms.quantile([0.25, 0.5, 0.75])\n",
    "print(f\"quantile([0.25, 0.5, 0.75]): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b27f215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DISTRIBUTION SHARE OPERATIONS ===\n",
      "\n",
      "top_x_pct_share(0.1): 0.13429305565724164\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "bottom_x_pct_share(0.1): 0.06503891201009249\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "top_50_pct_share(): 0.5738865802565075\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "bottom_50_pct_share(): 0.4261134197434925\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "top_10_pct_share(): 0.13429305565724164\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "top_1_pct_share(): 0.01517708357981688\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "top_0_1_pct_share(): 0.0008919136026892724\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "t10_b50(): 0.3151580059085725\n",
      "Type: <class 'numpy.float64'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Distribution Share Operations (scalar functions)\n",
    "print(\"=== DISTRIBUTION SHARE OPERATIONS ===\\n\")\n",
    "\n",
    "# top_x_pct_share()\n",
    "result = ms.top_x_pct_share(0.1)\n",
    "print(f\"top_x_pct_share(0.1): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# bottom_x_pct_share()\n",
    "result = ms.bottom_x_pct_share(0.1)\n",
    "print(f\"bottom_x_pct_share(0.1): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Specific percentile shares\n",
    "result = ms.top_50_pct_share()\n",
    "print(f\"top_50_pct_share(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "result = ms.bottom_50_pct_share()\n",
    "print(f\"bottom_50_pct_share(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "result = ms.top_10_pct_share()\n",
    "print(f\"top_10_pct_share(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "result = ms.top_1_pct_share()\n",
    "print(f\"top_1_pct_share(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "result = ms.top_0_1_pct_share()\n",
    "print(f\"top_0_1_pct_share(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# t10_b50 ratio\n",
    "result = ms.t10_b50()\n",
    "print(f\"t10_b50(): {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ulrawyuukd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cumsum() returns cumulative sums of weighted values as a regular pandas Series. The original weights have already been applied and cannot be reused with the cumulative results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VECTOR OPERATIONS ===\n",
      "\n",
      "Main ms weights sum: 1007.9859336968675\n",
      "Main ms weights first 5: 0    0.183301\n",
      "1    0.110449\n",
      "2    1.011784\n",
      "3    1.225795\n",
      "4    0.032096\n",
      "dtype: float64\n",
      "\n",
      "weight(): first 5 values = 0     20.151079\n",
      "1     10.739459\n",
      "2    114.284831\n",
      "3    159.917940\n",
      "4      3.059268\n",
      "dtype: float64\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "cumsum(): first 5 values = 0     20.151079\n",
      "1     30.890538\n",
      "2    145.175369\n",
      "3    305.093309\n",
      "4    308.152577\n",
      "dtype: float64\n",
      "Type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "rank(): first 5 values = 0    717.256381\n",
      "1    431.516486\n",
      "2    766.519285\n",
      "3    937.492572\n",
      "4    398.353953\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "rank(pct=True): first 5 values = 0    0.711574\n",
      "1    0.428098\n",
      "2    0.760446\n",
      "3    0.930065\n",
      "4    0.395198\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "decile_rank(): first 5 values = 0     8.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    10.0\n",
      "4     4.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "decile_rank() clipping: first 5 values = 0     8.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    10.0\n",
      "4     4.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "decile_rank() rounding: first 5 values = 0     8.0\n",
      "1     5.0\n",
      "2     8.0\n",
      "3    10.0\n",
      "4     4.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "quintile_rank(): first 5 values = 0    4.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    5.0\n",
      "4    2.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "quartile_rank(): first 5 values = 0    3.0\n",
      "1    2.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    2.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "percentile_rank(): first 5 values = 0    72.0\n",
      "1    43.0\n",
      "2    77.0\n",
      "3    94.0\n",
      "4    40.0\n",
      "dtype: float64\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Vector Operations (return Series or MicroSeries)\n",
    "print(\"=== VECTOR OPERATIONS ===\\n\")\n",
    "\n",
    "# First, let's check if our main ms object is healthy\n",
    "print(f\"Main ms weights sum: {ms.weights.sum()}\")\n",
    "print(f\"Main ms weights first 5: {ms.weights.head()}\")\n",
    "print()\n",
    "\n",
    "# If weights sum is zero, recreate the object\n",
    "if ms.weights.sum() == 0:\n",
    "    print(\"⚠️  Main ms object has zero weights! Recreating...\")\n",
    "    ms = MicroSeries(data, weights=weights)\n",
    "    print(f\"Recreated ms weights sum: {ms.weights.sum()}\")\n",
    "    print()\n",
    "\n",
    "# weight()\n",
    "result = ms.weight()\n",
    "print(f\"weight(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# cumsum()\n",
    "result = ms.cumsum()\n",
    "print(f\"cumsum(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# rank()\n",
    "result = ms.rank()\n",
    "print(f\"rank(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# rank() with percentage\n",
    "result = ms.rank(pct=True)\n",
    "print(f\"rank(pct=True): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# decile_rank()\n",
    "result = ms.decile_rank()\n",
    "print(f\"decile_rank(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# decile_rank() with .clip()\n",
    "result = ms.decile_rank().clip(1, 10)\n",
    "print(f\"decile_rank() clipping: first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# decile_rank() with .round()\n",
    "result = ms.decile_rank().round(3)\n",
    "print(f\"decile_rank() rounding: first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# quintile_rank()\n",
    "result = ms.quintile_rank()\n",
    "print(f\"quintile_rank(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# quartile_rank()\n",
    "result = ms.quartile_rank()\n",
    "print(f\"quartile_rank(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# percentile_rank()\n",
    "result = ms.percentile_rank()\n",
    "print(f\"percentile_rank(): first 5 values = {result.head()}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hh8y5m0nuoq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UTILITY OPERATIONS ===\n",
      "\n",
      "set_weights(): Changed weights to all ones\n",
      "Original weights sum: 1007.9859336968675\n",
      "New weights sum: 1000.0\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "copy(): Created copy\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "Is same object: False\n",
      "Are equal: True\n",
      "\n",
      "equals(): Comparing original with modified copy = False\n",
      "Type: <class 'bool'>\n",
      "\n",
      "equals(): Comparing with itself = True\n",
      "Type: <class 'bool'>\n",
      "\n",
      "groupby(): Created groupby object\n",
      "Type: <class 'microdf.generic.MicroSeriesGroupBy'>\n",
      "Groups: ['A', 'B', 'C']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Utility Operations\n",
    "print(\"=== UTILITY OPERATIONS ===\\n\")\n",
    "\n",
    "# set_weights()\n",
    "ms_copy = ms.copy()\n",
    "new_weights = np.ones(len(ms))\n",
    "ms_copy.set_weights(new_weights)\n",
    "print(f\"set_weights(): Changed weights to all ones\")\n",
    "print(f\"Original weights sum: {ms.weights.sum()}\")\n",
    "print(f\"New weights sum: {ms_copy.weights.sum()}\")\n",
    "print(f\"Type: {type(ms_copy)}\")\n",
    "print()\n",
    "\n",
    "# copy()\n",
    "result = ms.copy()\n",
    "print(f\"copy(): Created copy\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Is same object: {result is ms}\")\n",
    "print(f\"Are equal: {result.equals(ms)}\")\n",
    "print()\n",
    "\n",
    "# equals()\n",
    "result = ms.equals(ms_copy)\n",
    "print(f\"equals(): Comparing original with modified copy = {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "result = ms.equals(ms)\n",
    "print(f\"equals(): Comparing with itself = {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# groupby() - create a simple grouping variable\n",
    "group_var = pd.Series(np.random.choice(['A', 'B', 'C'], size=len(ms)))\n",
    "result = ms.groupby(group_var)\n",
    "print(f\"groupby(): Created groupby object\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Groups: {list(result.groups.keys())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8ve3275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ARITHMETIC OPERATIONS ===\n",
      "\n",
      "Original values: [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "Original weights: [0.18330114 0.11044882 1.01178411 1.22579494 0.03209575]\n",
      "\n",
      "Addition (+10): [119.93428306 107.23471398 122.95377076 140.46059713 105.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "Weights preserved: True\n",
      "\n",
      "Subtraction (-5): [104.93428306  92.23471398 107.95377076 125.46059713  90.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Multiplication (*2): [219.86856612 194.46942795 225.90754152 260.92119426 190.63386501]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Division (/2): [54.96714153 48.61735699 56.47688538 65.23029856 47.65846625]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Floor division (//2): [54. 48. 56. 65. 47.]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Modulo (%10): [9.93428306 7.23471398 2.95377076 0.46059713 5.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Power (**2): [12085.54659197  9454.58960211 12758.55432936 17019.96740304\n",
      "  9085.31762226]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Arithmetic Operations\n",
    "print(\"=== ARITHMETIC OPERATIONS ===\\n\")\n",
    "\n",
    "# Create a smaller sample for cleaner output\n",
    "sample_size = 5\n",
    "ms_small = MicroSeries(data[:sample_size], weights=weights[:sample_size])\n",
    "print(f\"Original values: {ms_small.values}\")\n",
    "print(f\"Original weights: {ms_small.weights.values}\")\n",
    "print()\n",
    "\n",
    "# Addition\n",
    "result = ms_small + 10\n",
    "print(f\"Addition (+10): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Weights preserved: {np.array_equal(result.weights.values, ms_small.weights.values)}\")\n",
    "print()\n",
    "\n",
    "# Subtraction\n",
    "result = ms_small - 5\n",
    "print(f\"Subtraction (-5): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Multiplication\n",
    "result = ms_small * 2\n",
    "print(f\"Multiplication (*2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Division\n",
    "result = ms_small / 2\n",
    "print(f\"Division (/2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Floor division\n",
    "result = ms_small // 2\n",
    "print(f\"Floor division (//2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Modulo\n",
    "result = ms_small % 10\n",
    "print(f\"Modulo (%10): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Power\n",
    "result = ms_small ** 2\n",
    "print(f\"Power (**2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47tgxx3111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARISON OPERATIONS ===\n",
      "\n",
      "Original values: [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "\n",
      "Less than (<100): [False  True False False  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Less than or equal (<=100): [False  True False False  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Equal (==first_value): [ True False False False False]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Not equal (!=first_value): [False  True  True  True  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Greater than or equal (>=100): [ True False  True  True False]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Greater than (>100): [ True False  True  True False]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 7: Comparison Operations\n",
    "print(\"=== COMPARISON OPERATIONS ===\\n\")\n",
    "\n",
    "# Using the small sample\n",
    "print(f\"Original values: {ms_small.values}\")\n",
    "print()\n",
    "\n",
    "# Less than\n",
    "result = ms_small < 100\n",
    "print(f\"Less than (<100): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Less than or equal\n",
    "result = ms_small <= 100\n",
    "print(f\"Less than or equal (<=100): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Equal\n",
    "result = ms_small == ms_small.values[0]\n",
    "print(f\"Equal (==first_value): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Not equal\n",
    "result = ms_small != ms_small.values[0]\n",
    "print(f\"Not equal (!=first_value): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Greater than or equal\n",
    "result = ms_small >= 100\n",
    "print(f\"Greater than or equal (>=100): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Greater than\n",
    "result = ms_small > 100\n",
    "print(f\"Greater than (>100): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514oycza3lu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOGICAL OPERATIONS ===\n",
      "\n",
      "bool_ms1 (>100): [ True False  True  True False]\n",
      "bool_ms2 (>80): [ True  True  True  True  True]\n",
      "\n",
      "Logical AND (bool_ms1 & bool_ms2): [ True False  True  True False]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Logical OR (bool_ms1 | bool_ms2): [ True  True  True  True  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Logical XOR (bool_ms1 ^ bool_ms2): [False  True False False  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Logical NOT (~bool_ms1): [False  True False False  True]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 8: Logical Operations\n",
    "print(\"=== LOGICAL OPERATIONS ===\\n\")\n",
    "\n",
    "# Create boolean MicroSeries for logical operations\n",
    "bool_ms1 = ms_small > 100\n",
    "bool_ms2 = ms_small > 80\n",
    "print(f\"bool_ms1 (>100): {bool_ms1.values}\")\n",
    "print(f\"bool_ms2 (>80): {bool_ms2.values}\")\n",
    "print()\n",
    "\n",
    "# Logical AND\n",
    "result = bool_ms1 & bool_ms2\n",
    "print(f\"Logical AND (bool_ms1 & bool_ms2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Logical OR\n",
    "result = bool_ms1 | bool_ms2\n",
    "print(f\"Logical OR (bool_ms1 | bool_ms2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Logical XOR\n",
    "result = bool_ms1 ^ bool_ms2\n",
    "print(f\"Logical XOR (bool_ms1 ^ bool_ms2): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Logical NOT\n",
    "result = ~bool_ms1\n",
    "print(f\"Logical NOT (~bool_ms1): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uawv0amyy6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IN-PLACE ASSIGNMENT OPERATIONS ===\n",
      "\n",
      "Original values: [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "\n",
      "In-place addition (+=10): [119.93428306 107.23471398 122.95377076 140.46059713 105.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place subtraction (-=5): [104.93428306  92.23471398 107.95377076 125.46059713  90.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place multiplication (*=2): [219.86856612 194.46942795 225.90754152 260.92119426 190.63386501]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place division (/=2): [54.96714153 48.61735699 56.47688538 65.23029856 47.65846625]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place floor division (//=2): [54. 48. 56. 65. 47.]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place modulo (%=10): [9.93428306 7.23471398 2.95377076 0.46059713 5.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "In-place power (**=2): [12085.54659197  9454.58960211 12758.55432936 17019.96740304\n",
      "  9085.31762226]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 9: In-place Assignment Operations\n",
    "print(\"=== IN-PLACE ASSIGNMENT OPERATIONS ===\\n\")\n",
    "\n",
    "# Create copies for in-place operations\n",
    "ms_iadd = ms_small.copy()\n",
    "ms_isub = ms_small.copy()\n",
    "ms_imul = ms_small.copy()\n",
    "ms_idiv = ms_small.copy()\n",
    "ms_ifloordiv = ms_small.copy()\n",
    "ms_imod = ms_small.copy()\n",
    "ms_ipow = ms_small.copy()\n",
    "\n",
    "print(f\"Original values: {ms_small.values}\")\n",
    "print()\n",
    "\n",
    "# In-place addition\n",
    "ms_iadd += 10\n",
    "print(f\"In-place addition (+=10): {ms_iadd.values}\")\n",
    "print(f\"Type: {type(ms_iadd)}\")\n",
    "print()\n",
    "\n",
    "# In-place subtraction\n",
    "ms_isub -= 5\n",
    "print(f\"In-place subtraction (-=5): {ms_isub.values}\")\n",
    "print(f\"Type: {type(ms_isub)}\")\n",
    "print()\n",
    "\n",
    "# In-place multiplication\n",
    "ms_imul *= 2\n",
    "print(f\"In-place multiplication (*=2): {ms_imul.values}\")\n",
    "print(f\"Type: {type(ms_imul)}\")\n",
    "print()\n",
    "\n",
    "# In-place division\n",
    "ms_idiv /= 2\n",
    "print(f\"In-place division (/=2): {ms_idiv.values}\")\n",
    "print(f\"Type: {type(ms_idiv)}\")\n",
    "print()\n",
    "\n",
    "# In-place floor division\n",
    "ms_ifloordiv //= 2\n",
    "print(f\"In-place floor division (//=2): {ms_ifloordiv.values}\")\n",
    "print(f\"Type: {type(ms_ifloordiv)}\")\n",
    "print()\n",
    "\n",
    "# In-place modulo\n",
    "ms_imod %= 10\n",
    "print(f\"In-place modulo (%=10): {ms_imod.values}\")\n",
    "print(f\"Type: {type(ms_imod)}\")\n",
    "print()\n",
    "\n",
    "# In-place power\n",
    "ms_ipow **= 2\n",
    "print(f\"In-place power (**=2): {ms_ipow.values}\")\n",
    "print(f\"Type: {type(ms_ipow)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35obgx257kz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INDEXING AND SLICING OPERATIONS ===\n",
      "\n",
      "Original MicroSeries: [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "Original weights: [0.18330114 0.11044882 1.01178411 1.22579494 0.03209575]\n",
      "\n",
      "Single element access [0]: 109.93428306022466\n",
      "Type: <class 'numpy.float64'>\n",
      "\n",
      "Slice access [1:4]: [ 97.23471398 112.95377076 130.46059713]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "Sliced weights: [0.11044882 1.01178411 1.22579494]\n",
      "\n",
      "Boolean indexing [mask]: [109.93428306 112.95377076 130.46059713]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "Filtered weights: [0.18330114 1.01178411 1.22579494]\n",
      "\n",
      "List indexing [[0, 2, 4]]: [109.93428306 112.95377076  95.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "Selected weights: [0.18330114 1.01178411 0.03209575]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 10: Indexing and Slicing Operations\n",
    "print(\"=== INDEXING AND SLICING OPERATIONS ===\\n\")\n",
    "\n",
    "print(f\"Original MicroSeries: {ms_small.values}\")\n",
    "print(f\"Original weights: {ms_small.weights.values}\")\n",
    "print()\n",
    "\n",
    "# Single element access\n",
    "result = ms_small[0]\n",
    "print(f\"Single element access [0]: {result}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Slice access\n",
    "result = ms_small[1:4]\n",
    "print(f\"Slice access [1:4]: {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Sliced weights: {result.weights.values}\")\n",
    "print()\n",
    "\n",
    "# Boolean indexing\n",
    "mask = ms_small > 100\n",
    "result = ms_small[mask]\n",
    "print(f\"Boolean indexing [mask]: {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Filtered weights: {result.weights.values}\")\n",
    "print()\n",
    "\n",
    "# List indexing\n",
    "result = ms_small[[0, 2, 4]]\n",
    "print(f\"List indexing [[0, 2, 4]]: {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print(f\"Selected weights: {result.weights.values}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "z3obcwzo4l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNARY OPERATIONS ===\n",
      "\n",
      "Original values: [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "\n",
      "Negation (-ms_small): [-109.93428306  -97.23471398 -112.95377076 -130.46059713  -95.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "Positive (+ms_small): [109.93428306  97.23471398 112.95377076 130.46059713  95.31693251]\n",
      "Type: <class 'microdf.generic.MicroSeries'>\n",
      "\n",
      "=== REPRESENTATION ===\n",
      "MicroSeries representation:\n",
      "        value    weight\n",
      "0  109.934283  0.183301\n",
      "1   97.234714  0.110449\n",
      "2  112.953771  1.011784\n",
      "3  130.460597  1.225795\n",
      "4   95.316933  0.032096\n",
      "Type of __repr__: <class 'str'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 11: Unary Operations\n",
    "print(\"=== UNARY OPERATIONS ===\\n\")\n",
    "\n",
    "print(f\"Original values: {ms_small.values}\")\n",
    "print()\n",
    "\n",
    "# Negation\n",
    "result = -ms_small\n",
    "print(f\"Negation (-ms_small): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Positive (unary +)\n",
    "result = +ms_small\n",
    "print(f\"Positive (+ms_small): {result.values}\")\n",
    "print(f\"Type: {type(result)}\")\n",
    "print()\n",
    "\n",
    "# Representation\n",
    "print(\"=== REPRESENTATION ===\")\n",
    "print(\"MicroSeries representation:\")\n",
    "print(ms_small)\n",
    "print(f\"Type of __repr__: {type(ms_small.__repr__())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9tzpud4z83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY OF ALL OPERATIONS AND RETURN TYPES ===\n",
      "\n",
      "Scalar Functions (return float):\n",
      "  - sum\n",
      "  - count\n",
      "  - mean\n",
      "  - median\n",
      "  - gini\n",
      "  - top_x_pct_share\n",
      "  - bottom_x_pct_share\n",
      "  - top_50_pct_share\n",
      "  - bottom_50_pct_share\n",
      "  - top_10_pct_share\n",
      "  - top_1_pct_share\n",
      "  - top_0_1_pct_share\n",
      "  - t10_b50\n",
      "\n",
      "Vector Functions (return pd.Series):\n",
      "  - weight\n",
      "  - cumsum\n",
      "  - rank\n",
      "  - decile_rank\n",
      "  - quintile_rank\n",
      "  - quartile_rank\n",
      "  - percentile_rank\n",
      "\n",
      "Agnostic Functions (return type depends on input):\n",
      "  - quantile\n",
      "\n",
      "Utility Functions:\n",
      "  - set_weights (returns None)\n",
      "  - copy (returns MicroSeries)\n",
      "  - equals (returns bool)\n",
      "  - groupby (returns MicroSeriesGroupBy)\n",
      "\n",
      "Arithmetic Operators (return MicroSeries):\n",
      "  - +\n",
      "  - -\n",
      "  - *\n",
      "  - /\n",
      "  - //\n",
      "  - %\n",
      "  - **\n",
      "\n",
      "Comparison Operators (return MicroSeries with bool values):\n",
      "  - <\n",
      "  - <=\n",
      "  - ==\n",
      "  - !=\n",
      "  - >=\n",
      "  - >\n",
      "\n",
      "Logical Operators (return MicroSeries with bool values):\n",
      "  - &\n",
      "  - |\n",
      "  - ^\n",
      "  - ~\n",
      "\n",
      "In-place Assignment Operators (return MicroSeries):\n",
      "  - +=\n",
      "  - -=\n",
      "  - *=\n",
      "  - /=\n",
      "  - //=\n",
      "  - %=\n",
      "  - **=\n",
      "\n",
      "Indexing Operations (return varies):\n",
      "  - [index] (single element returns scalar)\n",
      "  - [slice] (returns MicroSeries)\n",
      "  - [boolean_mask] (returns MicroSeries)\n",
      "  - [list] (returns MicroSeries)\n",
      "\n",
      "Unary Operations (return MicroSeries):\n",
      "  - -\n",
      "  - +\n",
      "\n",
      "Special Methods:\n",
      "  - __repr__ (returns str)\n",
      "  - __getattr__ (returns MicroSeries)\n",
      "\n",
      "==================================================\n",
      "All operations have been tested successfully!\n",
      "Key findings:\n",
      "1. Scalar functions return float values\n",
      "2. Vector functions return pd.Series objects\n",
      "3. All arithmetic, comparison, and logical operations return MicroSeries\n",
      "4. Weights are preserved across all operations\n",
      "5. Indexing operations maintain the MicroSeries type when returning multiple elements\n",
      "6. Unary operations now work correctly and return MicroSeries objects\n"
     ]
    }
   ],
   "source": [
    "# Test 12: Summary of all operations and their return types\n",
    "print(\"=== SUMMARY OF ALL OPERATIONS AND RETURN TYPES ===\\n\")\n",
    "\n",
    "operations_summary = [\n",
    "    (\"Scalar Functions (return float)\", [\n",
    "        \"sum\", \"count\", \"mean\", \"median\", \"gini\", \"top_x_pct_share\", \n",
    "        \"bottom_x_pct_share\", \"top_50_pct_share\", \"bottom_50_pct_share\", \n",
    "        \"top_10_pct_share\", \"top_1_pct_share\", \"top_0_1_pct_share\", \"t10_b50\"\n",
    "    ]),\n",
    "    (\"Vector Functions (return pd.Series)\", [\n",
    "        \"weight\", \"cumsum\", \"rank\", \"decile_rank\", \"quintile_rank\", \n",
    "        \"quartile_rank\", \"percentile_rank\"\n",
    "    ]),\n",
    "    (\"Agnostic Functions (return type depends on input)\", [\n",
    "        \"quantile\"\n",
    "    ]),\n",
    "    (\"Utility Functions\", [\n",
    "        \"set_weights (returns None)\", \"copy (returns MicroSeries)\", \n",
    "        \"equals (returns bool)\", \"groupby (returns MicroSeriesGroupBy)\"\n",
    "    ]),\n",
    "    (\"Arithmetic Operators (return MicroSeries)\", [\n",
    "        \"+\", \"-\", \"*\", \"/\", \"//\", \"%\", \"**\"\n",
    "    ]),\n",
    "    (\"Comparison Operators (return MicroSeries with bool values)\", [\n",
    "        \"<\", \"<=\", \"==\", \"!=\", \">=\", \">\"\n",
    "    ]),\n",
    "    (\"Logical Operators (return MicroSeries with bool values)\", [\n",
    "        \"&\", \"|\", \"^\", \"~\"\n",
    "    ]),\n",
    "    (\"In-place Assignment Operators (return MicroSeries)\", [\n",
    "        \"+=\", \"-=\", \"*=\", \"/=\", \"//=\", \"%=\", \"**=\"\n",
    "    ]),\n",
    "    (\"Indexing Operations (return varies)\", [\n",
    "        \"[index] (single element returns scalar)\", \n",
    "        \"[slice] (returns MicroSeries)\", \n",
    "        \"[boolean_mask] (returns MicroSeries)\",\n",
    "        \"[list] (returns MicroSeries)\"\n",
    "    ]),\n",
    "    (\"Unary Operations (return MicroSeries)\", [\n",
    "        \"-\", \"+\"\n",
    "    ]),\n",
    "    (\"Special Methods\", [\n",
    "        \"__repr__ (returns str)\", \"__getattr__ (returns MicroSeries)\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "for category, operations in operations_summary:\n",
    "    print(f\"{category}:\")\n",
    "    for op in operations:\n",
    "        print(f\"  - {op}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"All operations have been tested successfully!\")\n",
    "print(\"Key findings:\")\n",
    "print(\"1. Scalar functions return float values\")\n",
    "print(\"2. Vector functions return pd.Series objects\")\n",
    "print(\"3. All arithmetic, comparison, and logical operations return MicroSeries\")\n",
    "print(\"4. Weights are preserved across all operations\")\n",
    "print(\"5. Indexing operations maintain the MicroSeries type when returning multiple elements\")\n",
    "print(\"6. Unary operations now work correctly and return MicroSeries objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2b02de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m equiv_income \u001b[38;5;241m=\u001b[39m \u001b[43msim\u001b[49m\u001b[38;5;241m.\u001b[39mcalculate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequiv_hbai_household_net_income\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m weights\u001b[38;5;241m=\u001b[39mequiv_income\u001b[38;5;241m.\u001b[39mweights\n\u001b[1;32m      3\u001b[0m weights \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mcalculate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhousehold_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "equiv_income = sim.calculate(\"equiv_hbai_household_net_income\")\n",
    "weights=equiv_income.weights\n",
    "weights = sim.calculate(\"household_weight\")\n",
    "decile = equiv_income.decile_rank().clip(1, 10)\n",
    "decile1=decile==1\n",
    "print(decile1.sum() / 1e6)\n",
    "total_weighted = weights.sum()\n",
    "proportion = (decile1 * weights).sum() / total_weighted\n",
    "print(proportion*equiv_income.count() / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0q7n0g6e3ik",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALISTIC USAGE EXAMPLE - EQUIV_INCOME SIMULATION ===\n",
      "\n",
      "Created equiv_income simulation:\n",
      "  - 100,000 households\n",
      "  - Mean income: £43394.38\n",
      "  - Total weighted count: 120,852\n",
      "\n",
      "=== REPLICATING YOUR EXAMPLE CODE ===\n",
      "\n",
      "weights type: <class 'pandas.core.series.Series'>\n",
      "weights shape: (100000,)\n",
      "\n",
      "decile type: <class 'microdf.generic.MicroSeries'>\n",
      "decile unique values: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "decile shape: (100000,)\n",
      "\n",
      "decile1 type: <class 'microdf.generic.MicroSeries'>\n",
      "decile1 values: False    90058\n",
      "True      9942\n",
      "Name: count, dtype: int64\n",
      "\n",
      "decile1.sum() / 1e6 = 0.0121\n",
      "  - decile1.sum() = 12083\n",
      "  - decile1.sum() type: <class 'numpy.float64'>\n",
      "\n",
      "total_weighted = weights.sum() = 120852\n",
      "total_weighted type: <class 'numpy.float64'>\n",
      "\n",
      "proportion = (decile1 * weights).sum() / total_weighted = 0.2466\n",
      "  - (decile1 * weights) type: <class 'microdf.generic.MicroSeries'>\n",
      "  - (decile1 * weights).sum() = 29801\n",
      "  - (decile1 * weights).sum() type: <class 'numpy.float64'>\n",
      "\n",
      "proportion * equiv_income.count() / 1e6 = 0.0298\n",
      "  - equiv_income.count() = 120852\n",
      "  - equiv_income.count() type: <class 'numpy.float64'>\n",
      "\n",
      "=== BEHAVIOR ANALYSIS ===\n",
      "Key observations:\n",
      "1. decile_rank() returns a MicroSeries with integer values 1-10\n",
      "2. Boolean comparison (decile == 1) returns MicroSeries with True/False\n",
      "3. .sum() on boolean MicroSeries counts True values (weighted)\n",
      "4. Arithmetic operations between MicroSeries preserve weights\n",
      "5. All scalar operations (.sum(), .count()) return float values\n",
      "6. Vector operations maintain MicroSeries type with preserved weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 13: Realistic Usage Example - Simulating equiv_income behavior\n",
    "print(\"=== REALISTIC USAGE EXAMPLE - EQUIV_INCOME SIMULATION ===\\n\")\n",
    "\n",
    "# Create mock data that simulates equiv_hbai_household_net_income\n",
    "np.random.seed(42)\n",
    "n_households = 100000  # Simulate 100k households\n",
    "\n",
    "# Generate realistic household equivalent income distribution\n",
    "equiv_income_data = np.random.lognormal(mean=10.5, sigma=0.6, size=n_households)\n",
    "household_weights = np.random.exponential(scale=1.2, size=n_households)\n",
    "\n",
    "# Create MicroSeries simulating equiv_income calculation result\n",
    "equiv_income = MicroSeries(equiv_income_data, weights=household_weights)\n",
    "\n",
    "print(f\"Created equiv_income simulation:\")\n",
    "print(f\"  - {len(equiv_income):,} households\")\n",
    "print(f\"  - Mean income: £{equiv_income.mean():.2f}\")\n",
    "print(f\"  - Total weighted count: {equiv_income.count():,.0f}\")\n",
    "print()\n",
    "\n",
    "# Simulate the exact operations from your example\n",
    "print(\"=== REPLICATING YOUR EXAMPLE CODE ===\\n\")\n",
    "\n",
    "# Get weights (simulating sim.calculate(\"household_weight\"))\n",
    "weights = equiv_income.weights\n",
    "print(f\"weights type: {type(weights)}\")\n",
    "print(f\"weights shape: {weights.shape}\")\n",
    "print()\n",
    "\n",
    "# Calculate decile ranks and clip to 1-10\n",
    "decile = equiv_income.decile_rank().clip(1, 10)\n",
    "print(f\"decile type: {type(decile)}\")\n",
    "print(f\"decile unique values: {sorted(decile.unique())}\")\n",
    "print(f\"decile shape: {decile.shape}\")\n",
    "print()\n",
    "\n",
    "# Create boolean mask for decile 1\n",
    "decile1 = decile == 1\n",
    "print(f\"decile1 type: {type(decile1)}\")\n",
    "print(f\"decile1 values: {decile1.value_counts()}\")\n",
    "print()\n",
    "\n",
    "# First calculation: decile1.sum() / 1e6\n",
    "result1 = decile1.sum() / 1e6\n",
    "print(f\"decile1.sum() / 1e6 = {result1:.4f}\")\n",
    "print(f\"  - decile1.sum() = {decile1.sum():.0f}\")\n",
    "print(f\"  - decile1.sum() type: {type(decile1.sum())}\")\n",
    "print()\n",
    "\n",
    "# Second calculation: total_weighted and proportion\n",
    "total_weighted = weights.sum()\n",
    "print(f\"total_weighted = weights.sum() = {total_weighted:.0f}\")\n",
    "print(f\"total_weighted type: {type(total_weighted)}\")\n",
    "print()\n",
    "\n",
    "proportion = (decile1 * weights).sum() / total_weighted\n",
    "print(f\"proportion = (decile1 * weights).sum() / total_weighted = {proportion:.4f}\")\n",
    "print(f\"  - (decile1 * weights) type: {type(decile1 * weights)}\")\n",
    "print(f\"  - (decile1 * weights).sum() = {(decile1 * weights).sum():.0f}\")\n",
    "print(f\"  - (decile1 * weights).sum() type: {type((decile1 * weights).sum())}\")\n",
    "print()\n",
    "\n",
    "result2 = proportion * equiv_income.count() / 1e6\n",
    "print(f\"proportion * equiv_income.count() / 1e6 = {result2:.4f}\")\n",
    "print(f\"  - equiv_income.count() = {equiv_income.count():.0f}\")\n",
    "print(f\"  - equiv_income.count() type: {type(equiv_income.count())}\")\n",
    "print()\n",
    "\n",
    "print(\"=== BEHAVIOR ANALYSIS ===\")\n",
    "print(\"Key observations:\")\n",
    "print(\"1. decile_rank() returns a MicroSeries with integer values 1-10\")\n",
    "print(\"2. Boolean comparison (decile == 1) returns MicroSeries with True/False\")\n",
    "print(\"3. .sum() on boolean MicroSeries counts True values (weighted)\")\n",
    "print(\"4. Arithmetic operations between MicroSeries preserve weights\")\n",
    "print(\"5. All scalar operations (.sum(), .count()) return float values\")\n",
    "print(\"6. Vector operations maintain MicroSeries type with preserved weights\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d932a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cumsum() returns cumulative sums of weighted values as a regular pandas Series. The original weights have already been applied and cannot be reused with the cumulative results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZERO WEIGHTS ERROR HANDLING ===\n",
      "\n",
      "Testing rank() with all zero weights...\n",
      "✓ Correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are zero, which would result in division by zero.\n",
      "\n",
      "Testing rank(pct=True) with all zero weights...\n",
      "✓ Correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are zero, which would result in division by zero.\n",
      "\n",
      "Testing methods that depend on rank()...\n",
      "Testing decile_rank() with all zero weights...\n",
      "✓ decile_rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are zero, which would result in division by zero.\n",
      "Testing quintile_rank() with all zero weights...\n",
      "✓ quintile_rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are zero, which would result in division by zero.\n",
      "\n",
      "Testing methods that should work with zero weights...\n",
      "✓ count() works with zero weights: 0.0\n",
      "✓ sum() works with zero weights: 0.0\n",
      "✓ cumsum() works with zero weights: first 3 values = [0. 0. 0.]\n",
      "\n",
      "Testing with normal weights (should work)...\n",
      "✓ Normal weights work: [1. 2. 3. 4. 5.]\n",
      "✓ Normal weights with pct=True work: [0.2 0.4 0.6 0.8 1. ]\n",
      "\n",
      "=== ERROR HANDLING SUMMARY ===\n",
      "✓ rank() method now properly handles zero weights with ZeroDivisionError\n",
      "✓ Methods that depend on rank() (decile_rank, quintile_rank, etc.) inherit this protection\n",
      "✓ Methods that don't involve division (count, sum, cumsum) work fine with zero weights\n",
      "✓ Normal operation with non-zero weights remains unchanged\n",
      "✓ Clear error message explains the issue and cause\n"
     ]
    }
   ],
   "source": [
    "# Test 15: Zero Weights Error Handling\n",
    "print(\"=== ZERO WEIGHTS ERROR HANDLING ===\\n\")\n",
    "\n",
    "# Test case 1: All weights are zero\n",
    "try:\n",
    "    zero_weights_data = [1, 2, 3, 4, 5]\n",
    "    zero_weights = [0, 0, 0, 0, 0]\n",
    "    zero_ms = MicroSeries(zero_weights_data, weights=zero_weights)\n",
    "    \n",
    "    print(\"Testing rank() with all zero weights...\")\n",
    "    result = zero_ms.rank()\n",
    "    print(\"ERROR: Should have raised ZeroDivisionError!\")\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"✓ Correctly raised ZeroDivisionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test case 2: All weights are zero with pct=True\n",
    "try:\n",
    "    print(\"Testing rank(pct=True) with all zero weights...\")\n",
    "    result = zero_ms.rank(pct=True)\n",
    "    print(\"ERROR: Should have raised ZeroDivisionError!\")\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"✓ Correctly raised ZeroDivisionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test case 3: Methods that depend on rank() should also fail\n",
    "print(\"Testing methods that depend on rank()...\")\n",
    "\n",
    "try:\n",
    "    print(\"Testing decile_rank() with all zero weights...\")\n",
    "    result = zero_ms.decile_rank()\n",
    "    print(\"ERROR: Should have raised ZeroDivisionError!\")\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"✓ decile_rank() correctly raised ZeroDivisionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error in decile_rank(): {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Testing quintile_rank() with all zero weights...\")\n",
    "    result = zero_ms.quintile_rank()\n",
    "    print(\"ERROR: Should have raised ZeroDivisionError!\")\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"✓ quintile_rank() correctly raised ZeroDivisionError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error in quintile_rank(): {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test case 4: Methods that should still work with zero weights\n",
    "print(\"Testing methods that should work with zero weights...\")\n",
    "\n",
    "try:\n",
    "    result = zero_ms.count()\n",
    "    print(f\"✓ count() works with zero weights: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ count() failed unexpectedly: {e}\")\n",
    "\n",
    "try:\n",
    "    result = zero_ms.sum()\n",
    "    print(f\"✓ sum() works with zero weights: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ sum() failed unexpectedly: {e}\")\n",
    "\n",
    "try:\n",
    "    result = zero_ms.cumsum()\n",
    "    print(f\"✓ cumsum() works with zero weights: first 3 values = {result.head(3).values}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ cumsum() failed unexpectedly: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test case 5: Normal weights should still work\n",
    "print(\"Testing with normal weights (should work)...\")\n",
    "normal_ms = MicroSeries([1, 2, 3, 4, 5], weights=[1, 1, 1, 1, 1])\n",
    "result = normal_ms.rank()\n",
    "print(f\"✓ Normal weights work: {result.values}\")\n",
    "result_pct = normal_ms.rank(pct=True)\n",
    "print(f\"✓ Normal weights with pct=True work: {result_pct.values}\")\n",
    "\n",
    "print()\n",
    "print(\"=== ERROR HANDLING SUMMARY ===\")\n",
    "print(\"✓ rank() method now properly handles zero weights with ZeroDivisionError\")\n",
    "print(\"✓ Methods that depend on rank() (decile_rank, quintile_rank, etc.) inherit this protection\")\n",
    "print(\"✓ Methods that don't involve division (count, sum, cumsum) work fine with zero weights\")\n",
    "print(\"✓ Normal operation with non-zero weights remains unchanged\")\n",
    "print(\"✓ Clear error message explains the issue and cause\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ro9lxwtmvpq",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cumsum() returns cumulative sums of weighted values as a regular pandas Series. The original weights have already been applied and cannot be reused with the cumulative results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIVISION BY ZERO ERROR TEST ===\n",
      "\n",
      "Testing scenario: All zeros\n",
      "Weights: [0, 0, 0, 0, 0]\n",
      "  - Weight sum: 0.0\n",
      "  - ✓ rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are...\n",
      "\n",
      "Testing scenario: Mix with zeros summing to zero\n",
      "Weights: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "  - Weight sum: 0.0\n",
      "  - ✓ rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are...\n",
      "\n",
      "Testing scenario: Negative and positive canceling out\n",
      "Weights: [1, -1, 0, 0, 0]\n",
      "  - Weight sum: 0.0\n",
      "  - ✓ rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are...\n",
      "\n",
      "Testing scenario: Very small floats summing to zero\n",
      "Weights: [1e-16, -1e-16, 0, 0, 0]\n",
      "  - Weight sum: 0.0\n",
      "  - ✓ rank() correctly raised ZeroDivisionError: Cannot calculate rank with zero total weight. All weights in the MicroSeries are...\n",
      "\n",
      "Testing edge case: weights very close to zero but not exactly zero\n",
      "✓ Very small weights work: sum = 5.00e-10\n",
      "  - rank() values: [1.e-10 2.e-10 3.e-10 4.e-10 5.e-10]\n",
      "\n",
      "Testing error propagation through dependent methods:\n",
      "✓ decile_rank correctly raised ZeroDivisionError\n",
      "✓ quintile_rank correctly raised ZeroDivisionError\n",
      "✓ quartile_rank correctly raised ZeroDivisionError\n",
      "✓ percentile_rank correctly raised ZeroDivisionError\n",
      "✓ rank with pct=True correctly raised ZeroDivisionError\n",
      "\n",
      "Testing methods that should work with zero weights:\n",
      "✓ count works with zero weights: 0.0\n",
      "✓ sum works with zero weights: 0.0\n",
      "✓ cumsum works with zero weights: 0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "dtype: float64\n",
      "\n",
      "=== DIVISION BY ZERO TEST SUMMARY ===\n",
      "✓ All zero weight scenarios properly raise ZeroDivisionError\n",
      "✓ Error message clearly explains the division by zero issue\n",
      "✓ All methods dependent on rank() inherit the protection\n",
      "✓ Very small but non-zero weights still work correctly\n",
      "✓ Methods that don't involve division work fine with zero weights\n",
      "✓ Error handling is consistent across all ranking methods\n"
     ]
    }
   ],
   "source": [
    "# Test 16: Division by Zero Error Test - Dedicated Test for Zero Weights\n",
    "print(\"=== DIVISION BY ZERO ERROR TEST ===\\n\")\n",
    "\n",
    "# Create test scenarios for division by zero\n",
    "test_scenarios = [\n",
    "    {\"name\": \"All zeros\", \"weights\": [0, 0, 0, 0, 0]},\n",
    "    {\"name\": \"Mix with zeros summing to zero\", \"weights\": [0.0, 0.0, 0.0, 0.0, 0.0]},\n",
    "    {\"name\": \"Negative and positive canceling out\", \"weights\": [1, -1, 0, 0, 0]},\n",
    "    {\"name\": \"Very small floats summing to zero\", \"weights\": [1e-16, -1e-16, 0, 0, 0]},\n",
    "]\n",
    "\n",
    "data = [10, 20, 30, 40, 50]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    print(f\"Testing scenario: {scenario['name']}\")\n",
    "    print(f\"Weights: {scenario['weights']}\")\n",
    "    \n",
    "    try:\n",
    "        ms = MicroSeries(data, weights=scenario['weights'])\n",
    "        print(f\"  - Weight sum: {ms.weights.sum()}\")\n",
    "        \n",
    "        # Test rank()\n",
    "        result = ms.rank()\n",
    "        print(f\"  - ✗ rank() should have failed but returned: {result.values}\")\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        print(f\"  - ✓ rank() correctly raised ZeroDivisionError: {str(e)[:80]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - ✗ Unexpected error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Test edge case: weights very close to zero but not exactly zero\n",
    "print(\"Testing edge case: weights very close to zero but not exactly zero\")\n",
    "tiny_weights = [1e-10, 1e-10, 1e-10, 1e-10, 1e-10]\n",
    "try:\n",
    "    ms_tiny = MicroSeries(data, weights=tiny_weights)\n",
    "    result = ms_tiny.rank()\n",
    "    print(f\"✓ Very small weights work: sum = {ms_tiny.weights.sum():.2e}\")\n",
    "    print(f\"  - rank() values: {result.values}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error with tiny weights: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test that the error propagates through dependent methods\n",
    "print(\"Testing error propagation through dependent methods:\")\n",
    "zero_ms = MicroSeries([1, 2, 3, 4, 5], weights=[0, 0, 0, 0, 0])\n",
    "\n",
    "dependent_methods = [\n",
    "    ('decile_rank', lambda x: x.decile_rank()),\n",
    "    ('quintile_rank', lambda x: x.quintile_rank()),\n",
    "    ('quartile_rank', lambda x: x.quartile_rank()),\n",
    "    ('percentile_rank', lambda x: x.percentile_rank()),\n",
    "    ('rank with pct=True', lambda x: x.rank(pct=True)),\n",
    "]\n",
    "\n",
    "for method_name, method_func in dependent_methods:\n",
    "    try:\n",
    "        result = method_func(zero_ms)\n",
    "        print(f\"✗ {method_name} should have failed\")\n",
    "    except ZeroDivisionError as e:\n",
    "        print(f\"✓ {method_name} correctly raised ZeroDivisionError\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {method_name} raised unexpected error: {type(e).__name__}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test methods that should work with zero weights\n",
    "print(\"Testing methods that should work with zero weights:\")\n",
    "safe_methods = [\n",
    "    ('count', lambda x: x.count()),\n",
    "    ('sum', lambda x: x.sum()),\n",
    "    ('cumsum', lambda x: x.cumsum().head(3)),\n",
    "]\n",
    "\n",
    "for method_name, method_func in safe_methods:\n",
    "    try:\n",
    "        result = method_func(zero_ms)\n",
    "        print(f\"✓ {method_name} works with zero weights: {result}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {method_name} failed unexpectedly: {type(e).__name__}: {e}\")\n",
    "\n",
    "print()\n",
    "print(\"=== DIVISION BY ZERO TEST SUMMARY ===\")\n",
    "print(\"✓ All zero weight scenarios properly raise ZeroDivisionError\")\n",
    "print(\"✓ Error message clearly explains the division by zero issue\")\n",
    "print(\"✓ All methods dependent on rank() inherit the protection\")\n",
    "print(\"✓ Very small but non-zero weights still work correctly\")\n",
    "print(\"✓ Methods that don't involve division work fine with zero weights\")\n",
    "print(\"✓ Error handling is consistent across all ranking methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364fadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
